{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score,make_scorer\n",
    "from ConstructDatatset import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from TotalCalculation import *\n",
    "from preprocessing import *\n",
    "from ClassPrediction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\ASUS\\\\Documents\\\\NARIT_internship_data\\\\CSV_dataset_sobel\\\\Dataset_06_2024'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mBuilddataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcateDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mASUS\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mNARIT_internship_data\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCSV_dataset_sobel\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDataset_06_2024\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df2 \u001b[38;5;241m=\u001b[39m Builddataset()\u001b[38;5;241m.\u001b[39mconcateDataset(folder_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mASUS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNARIT_internship_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCSV_dataset_sobel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataset_12_2023\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\NARIT_internship_2024\\NARIT_internship_2024\\ConstructDatatset.py:9\u001b[0m, in \u001b[0;36mBuilddataset.concateDataset\u001b[1;34m(self, folder_name)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcateDataset\u001b[39m(\u001b[38;5;28mself\u001b[39m,folder_name):\n\u001b[0;32m      8\u001b[0m     data_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     10\u001b[0m         name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_name,filename)\n\u001b[0;32m     11\u001b[0m         data_list\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mread_csv(name,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\ASUS\\\\Documents\\\\NARIT_internship_data\\\\CSV_dataset_sobel\\\\Dataset_06_2024'"
     ]
    }
   ],
   "source": [
    "df1 = Builddataset().concateDataset(folder_name = r'C:\\Users\\ASUS\\Documents\\NARIT_internship_data\\CSV_dataset_sobel\\Dataset_06_2024')\n",
    "df2 = Builddataset().concateDataset(folder_name = r'C:\\Users\\ASUS\\Documents\\NARIT_internship_data\\CSV_dataset_sobel\\Dataset_12_2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = []\n",
    "for i in df1.index.tolist():\n",
    "    date1.append(timeConvertion().ticks_to_datetime(i,time_zone=7))\n",
    "df1['Time'] = date1\n",
    "date2 = []\n",
    "for i in df2.index.tolist():\n",
    "    date2.append(timeConvertion().ticks_to_datetime(i,time_zone=7))\n",
    "df2['Time'] = date2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Time (decimal)'] = df1['Time'].dt.hour+df1['Time'].dt.minute/60\n",
    "df2['Time (decimal)'] = df2['Time'].dt.hour+df2['Time'].dt.minute/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name_y = str('Blue channel')\n",
    "name_x = np.arange(len(df))\n",
    "dintr = np.gradient(df['Blue channel'])\n",
    "dintb = np.gradient(df['Red channel'])\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "sns.lineplot(data=df,x=name_x,y=df[name_y],c='blue')\n",
    "sns.lineplot(data=df,x=name_x,y=df['Red channel'],c='green')\n",
    "sns.lineplot(data=df,x=name_x,y=df['intensity'])\n",
    "plt.plot(dintr)\n",
    "plt.plot(dintb,c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2024-01-01'\n",
    "end_date = str(df1['Time'].tolist()[1])\n",
    "location = [18.849417,98.9538]\n",
    "days = timeConvertion().time_duration(start_date,end_date,include_end_date=True).days\n",
    "\n",
    "LSTM = SunPosition.LSTM(time_zone_offset=7)\n",
    "EoT = SunPosition.calculate_EoT(day=days)\n",
    "TC = SunPosition.TimeCorrectionFactor(Longitude=location[1],LSTM=LSTM,EoT=EoT)\n",
    "dec = SunPosition.declination(day=days)\n",
    "suntime = SunPosition.DaytimeInfo(latitude=location[0],declination=dec,TC=TC)\n",
    "sunrise1,sunset1 = SunPosition.DaytimeInfo(latitude=location[0],declination=dec,TC=TC)\n",
    "\n",
    "start_date = '2023-01-01'\n",
    "end_date = str(df2['Time'].tolist()[1])\n",
    "location = [18.849417,98.9538]\n",
    "days = timeConvertion().time_duration(start_date,end_date,include_end_date=True).days\n",
    "\n",
    "LSTM = SunPosition.LSTM(time_zone_offset=7)\n",
    "EoT = SunPosition.calculate_EoT(day=days)\n",
    "TC = SunPosition.TimeCorrectionFactor(Longitude=location[1],LSTM=LSTM,EoT=EoT)\n",
    "dec = SunPosition.declination(day=days)\n",
    "suntime = SunPosition.DaytimeInfo(latitude=location[0],declination=dec,TC=TC)\n",
    "sunrise2,sunset2 = SunPosition.DaytimeInfo(latitude=location[0],declination=dec,TC=TC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = Builddataset().DayNightSplit(suntime=[sunrise1,sunset1],Mode='night',dataframe=df1)\n",
    "df2 = Builddataset().DayNightSplit(suntime=[sunrise2,sunset2],Mode='night',dataframe=df2)\n",
    "\n",
    "df = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['Time (decimal)','Time','correlation','Blue channel','Red channel','intensity'])\n",
    "\n",
    "dataset = list(x.itertuples(index=False,name=None))\n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data=x.corr(),cmap='jet',annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "np.random.seed(42)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=5, n_init=20, random_state=42, tol=1e-05,algorithm='lloyd')\n",
    "minik = MiniBatchKMeans(n_clusters=5,batch_size=1500, max_no_improvement=30, tol=1e-4, random_state=42, init='k-means++' ,n_init=10, max_iter=500 ,reassignment_ratio=0.001)\n",
    "#af = AffinityPropagation(damping=0.95, max_iter=500, convergence_iter=20, preference=-50, affinity='euclidean')\n",
    "GMM = GaussianMixture(n_components=7, tol=1e-4, init_params='kmeans',covariance_type='full', max_iter=500, random_state=42, n_init=10)\n",
    "labels = GMM.fit_predict(dataset)\n",
    "labels_kmean = kmeans.fit_predict(dataset)\n",
    "labels_minik = minik.fit_predict(dataset)\n",
    "#labels_af = af.fit_predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[:, 'Label_GMM'] = labels\n",
    "#df.loc[:, 'Label_Kmean'] = labels_kmean\n",
    "#df.loc[:, 'Label_AF'] = labels_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "sns.scatterplot(data=df,x=df['contrast'],y=df['energy'],hue=labels_minik,palette='rainbow')\n",
    "plt.subplot(1,2,2)\n",
    "sns.scatterplot(data=df,x=df['contrast'],y=df['energy'],hue=labels_kmean,palette='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(silhouette_score(dataset,labels_kmean))\n",
    "print(silhouette_score(dataset,labels_minik))\n",
    "#print(silhouette_score(dataset,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def silhouette_scorer(estimator, X):\n",
    "    cluster_labels = estimator.fit_predict(X)\n",
    "    return silhouette_score(X, cluster_labels)\n",
    "# Example adjustment for KMeans\n",
    "param_grid_kmeans = {\n",
    "    'tol' : [1e-4,1e-5,1e-6],\n",
    "    'n_clusters': [5, 7, 9, 11],\n",
    "    'init': ['k-means++', 'random'],\n",
    "    'n_init': [10, 20, 'auto'],\n",
    "    'max_iter': [300, 500, 700],\n",
    "    'algorithm' : ['lloyd','elkan']\n",
    "}\n",
    "grid_search_kmeans = GridSearchCV(KMeans(random_state=42), param_grid_kmeans, cv=5, scoring=silhouette_scorer)\n",
    "grid_search_kmeans.fit(dataset)  # X is your data\n",
    "\n",
    "best_kmeans = grid_search_kmeans.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(best_kmeans)\n",
    "#KMeans(n_clusters=5, n_init=20, random_state=42, tol=1e-05) : sobel\n",
    "#KMeans(init='k-means++', n_clusters=5, n_init=20, random_state=42, tol=1e-05,algorithm='lloyd')\n",
    "\n",
    "#MiniBatchKMeans(max_iter=300, n_clusters=5, n_init=10, random_state=42,tol=0.0001) : sobel\n",
    "#MiniBatchKMeans(n_clusters=5,batch_size=1500, max_no_improvement=30, tol=1e-4, random_state=42, init='k-means++' ,n_init=10, max_iter=500 ,reassignment_ratio=0.001)\n",
    "#--normal glcm---\n",
    "#MiniBatchKMeans(batch_size=500, max_iter=300, n_clusters=5, n_init=20,random_state=42, tol=1e-05) \\\\ same\n",
    "#KMeans(n_clusters=5, n_init='auto', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle \n",
    "\n",
    "with open('af_model_1.pkl','wb') as f:\n",
    "    pickle.dump(af,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open('gmm_model_6.pkl', 'wb') as f:\n",
    "    pickle.dump(GMM, f)\n",
    "with open('kmean_model_6.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans, f)\n",
    "with open('miniBkmean_model_6.pkl', 'wb') as f:\n",
    "    pickle.dump(minik, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import image\n",
    "image_list = image.getFilename(r'C:\\Users\\ASUS\\Documents\\NARIT_internship_data\\Test_folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filetime = []\n",
    "for file in image_list:\n",
    "    filetime.append(int(os.path.splitext(os.path.basename(file))[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viz = visualizer()\n",
    "number = 1\n",
    "source_folder = r'All_sky_camera_Astropark_Chaingmai\\2024-06\\2024-06-12'\n",
    "destination_folder = r'C:\\Users\\ASUS\\Documents\\NARIT_internship_2024\\Tester'\n",
    "\n",
    "viz.copy_matching_files(df=viz.match_label(df=df,number=number), source_folder=source_folder, destination_folder=destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred = prediction()\n",
    "path = r'All_sky_camera_Astropark_Chaingmai\\2024-06\\2024-06-09\\638534868144584540.png'\n",
    "pred_1,pred_2,cloud_percentage,sky_status,final = pred.total_prediction(image_path=path,mask_path='mask_delete_5.png',crop_size=570,kmeans=kmeans,GMM=GMM,df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask = cv2.imread('mask_delete_5.png',cv2.IMREAD_GRAYSCALE)\n",
    "mask = crop_center(img=mask,crop_size=570)\n",
    "img,name = load_single_image(path=path,crop_size=570,mask=mask,apply_crop_sun=False)\n",
    "image,value,RB = pred.RBsingle(input=img,dataframe=df)\n",
    "cloud_ratio = pred.CloudRatio(image=img,mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "def get_image_hash(image_data):\n",
    "    return hashlib.md5(image_data).hexdigest()\n",
    "\n",
    "image_url = \"http://weather.narit.or.th/images/allskyimage/ASTROPARK/2024-08-19\"\n",
    "previous_hash = None\n",
    "\n",
    "while True:\n",
    "    # Fetch the image from the web\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        # Get the current hash of the image\n",
    "        current_hash = get_image_hash(response.content)\n",
    "        \n",
    "        # Compare with the previous hash\n",
    "        if current_hash != previous_hash:\n",
    "            # The image has changed\n",
    "            print(\"Image has changed, updating display...\")\n",
    "            image_array = np.frombuffer(response.content, np.uint8)\n",
    "            image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "            cv2.imshow('Auto-Updated Image', image)\n",
    "            \n",
    "            # Update the previous hash\n",
    "            previous_hash = current_hash\n",
    "            \n",
    "            # Wait for 1 second to avoid rapid flickering\n",
    "            if cv2.waitKey(1000) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            print(\"No change detected.\")\n",
    "    \n",
    "    # Check every 10 seconds for a change\n",
    "    time.sleep(10)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
